import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten

# Generators (divides the dataset into batches)
# Only loads that batch into the RAM, then moves on to the next
train_ds = tf.keras.utils.image_dataset_from_directory(
    directory = r'C:\Users\bhanop1\Desktop\Code\Image-Classification-\datasets\dogs-vs-cats\dogs_vs_cats\train',
    labels = 'inferred',
    label_mode='int',  # Will assign 0 to cats and 1 to dogs
    batch_size=32,
    image_size=(256, 256)
)
validation_ds = tf.keras.utils.image_dataset_from_directory(
    directory = r'C:\Users\bhanop1\Desktop\Code\Image-Classification-\datasets\dogs-vs-cats\dogs_vs_cats\test',
    labels = 'inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256, 256)
)

#Normalize (a part of preprocessing)
def process(image, label):
    image=tf.cast(image/255. , tf.float32)
    return image,label

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process) 

#Create a CNN Model 
model = Sequential()

model.add(Conv2D(32,kernel_size=(3,3), padding='valid', activation='relu', input_shape=(256,256,3)))
'''A small grid (like 3x3 or 5x5) slides over the image, applying a mathematical operation (convolution) 
at each position. The result is a set of new images called feature maps that highlight where certain patterns are detected.'''

model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))
'''A pooling layer reduces the size of the feature maps, making the model more efficient and less prone to overfitting. It 
looks at small windows (like 2x2) in the feature map and takes the maximum value from each window.'''

model.add(Conv2D(64,kernel_size=(3,3), padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(128,kernel_size=(3,3), padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Flatten())
'''layer takes the multidimensional data from the previous layer (like 3D data from convolutional layers) and flattens it into a 1D array.'''

model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
'''ReLU (Rectified Linear Unit) is activation function that helps the model learn non-linear relationships. It sets all negative values to 
zero and keeps positive values unchanged.'''

model.add(Dense(1, activation='sigmoid'))
'''Sigmoid is an activation function that outputs values between 0 and 1. Itâ€™s ideal for binary classification tasks (like classifying images 
into two categories: cats or dogs).'''

# Compiling the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

''''adam' is an optimization algorithm that adjusts the model's weights to minimize the loss function.
'binary_crossentropy' is a loss function used for binary classification tasks, which measures the performance of the model.
['accuracy'] specifies that you want to track the accuracy of the model during training.'''

history = model.fit(train_ds,epochs=10,validation_data=validation_ds)